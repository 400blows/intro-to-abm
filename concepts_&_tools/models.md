# Models
Since our focus is on models, let us first discuss what we mean by a model. In fact, there are many kinds of models. A general classification is the distinction between formal mathematical models and non-formal models such as stories and cartoons. Sometimes people serve as role models for how one might live, such as [Nelson Mandela](http://en.wikipedia.org/wiki/Nelson_Mandela) or [Claudia Schiffer](http://en.wikipedia.org/wiki/Claudia_Schiffer). In this course we will only deal with formal models. The advantage of these formal models is that they are explicit and many of them are computer models that can be used to do repeated experiments.

Models are simplifications of reality. To make models we have to make decisions what to leave out of the model. What are the most important characteristics of the problem we like to describe? In making the simplifications we make assumptions how to simplify. We start to rely on theory and use theory to define what we need into our model. But there are different theories and different approaches to make assumptions.
We can develop formal models by using different approaches. Each modeling approach, in a broader context, involves its own set of theories, concepts, mathematical techniques, and accepted procedures for constructing and testing models. We can distinguish between deterministic and stochastic models, simulation and optimization models, reductionistic and integrated models, linear and non-linear models, one-agent and multi-agents models, and so on.

Instead of discussing all kinds of possible approaches, we want to discuss the difference between the reductionistic Newtonian approach and the complex adaptive systems approach. Since our course uses a complex adaptive system approach it is good to know how this differs from another frequently used approach. The basic difference is that a Newtonian approach assumes that a system, like the solar system, can be described as a clock. That is, it is mechanical and we can fully predict what will happen if we just have the right model. Complex adaptive models assume that there is no predictability of the full trajectory of the system. The system does not work like a clock, but like a flock of birds, constantly adjusting to changing contexts.

 ![newton](https://raw.githubusercontent.com/comses/intro-to-abm/master/assets/images/CH_2_Fig_1_newton.png)<br>*Figure 1: Issac Newton.*

Mathematical modeling has long been influenced by physical science, which has developed a mechanistic, reversible, reductionistic and equilibrium-based explanation of the world. This proved to be very successful in calculating trajectories of moving objects (e.g., cannon balls) and predicting the positions of celestial bodies. The work of [Isaac Newton](http://en.wikipedia.org/wiki/Isaac_Newton), culminating in the [Principia Mathematica Philosophiae Naturalis](http://en.wikipedia.org/wiki/Philosophi%C3%A6_Naturalis_Principia_Mathematica) in the late 17th century, was and still is very influential. In fact, Isaac Newton described the world as a machine for which we can predict its development if we understand all the mechanisms. Newton showed that he could explain and predict correctly the movement of planets around the sun. At least correct to an extent given the measurements they had at that moment in time.

The associated rational and mathematical way of describing the world around us was also applied during the last 100 years in the social sciences, economics and biology. Despite the fact that later developments in the natural sciences seriously constrained the applicability of the mechanistic paradigm, its relative simplicity had a great appeal to scientists from various disciplines working with models. However, despite the widespread use of this approach, the mechanistic paradigm is increasingly criticized. The foundations of the mechanistic view—reversibility, reductionism, and equilibrium-based and controllable experiments—have faded away in light of a number of “new” scientific insights. Basically we have to consider whether many of the systems in the life and social sciences can be described as a predictable machine.

First, the discovery of the [Second Law of Thermodynamics](http://en.wikipedia.org/wiki/Second_law_of_thermodynamics) brought down the notion of reversibility. The Second Law states that the entropy of a closed system is increasing. This means that heat flows from hot to cold, so that less useful energy remains. One of the consequences of the Second Law is the irreversibility of system behavior and the single direction of time. History matters!! Changes within systems cannot reverse back just like that (irreversible). This is in contrast to many mechanistic models, in which time can easily be reversed to calculate previous conditions.

![Benjamin Button](https://raw.githubusercontent.com/comses/intro-to-abm/master/assets/images/CH_2_Fig_2_button.png)<br>*Figure 2: Benjamin Button.*

If you let a glass fall it may break. It costs more energy to repair the glass than it cost to break it. When people become older parts of the body will degenerate. Our body can heal but scars of time will remain. Except in the case of the main character in the fantasy movie [Benjamin Button](http://en.wikipedia.org/wiki/The_Curious_Case_of_Benjamin_Button) played by Brad Pitt. Here a baby was born looking old, bald and wrinkled, and became more youthful over time.

Second, the equilibrium view of species was brought down by [Charles Darwin's](http://en.wikipedia.org/wiki/Charles_Darwin) book [*On the Origin of Species*](http://en.wikipedia.org/wiki/On_the_Origin_of_Species) during the mid-19th century. The static concept of unchanging species was replaced by a dynamic concept of evolution through natural selection and adaptation, thereby fundamentally changing our view of nature. Natural systems are in continuous disequilibrium, being interdependent and constantly adapting to changing circumstances.

Third, the theories of [quantum mechanics](http://en.wikipedia.org/wiki/Quantum_mechanics) have confronted us with a fundamental uncertainty regarding knowledge about systems, especially on the level of atoms and particles. The [uncertainty principle](http://en.wikipedia.org/wiki/Uncertainty_principle) of [Werner Heisenberg](http://en.wikipedia.org/wiki/Werner_Heisenberg) is well known, stating that it is impossible to simultaneously measure the position in space and momentum (mass times velocity) of any particle. The statement by [Pierre-Simon Laplace](http://en.wikipedia.org/wiki/Pierre-Simon_Laplace) in the early 19th century that if every position of every atom was known, the future might be predicted exactly, became therefore an illusion. Moreover, the notion of fundamental uncertainty implied that fully controlled experiments are strictly speaking not possible.

Notwithstanding the fact that these developments in the natural sciences changed our perception of the world, (mathematical) models are still frequently based on a mechanistic view of systems. Since the 19th century, scholars have studied systems that are irreversible, stochastic, out-of-equilibrium and holistic. Yet, since the 1960s, many examples have been found in nature, such as pendulum movement, chemical reactions, weather dynamics, and population ecology, which could be better explained by the new tools from complex systems. Complex system research focuses on finding simple underlying rules of complicated dynamics. Complex adaptive system research is a sub section of complex system research that focuses on systems of various interacting components that lead to emergent phenomena. Instead of the use of elegant analytical mathematics, as in the Newtonian approach to research, complex adaptive systems research is more dependent on the use of computer simulation. The reason for this is that we are not able to solve many of the models of the more complex non-linear systems by analytical equations and thus we approximate these models by simulations.
